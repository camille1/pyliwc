[
  {
    "objectID": "how-to-use.html",
    "href": "how-to-use.html",
    "title": "How to use",
    "section": "",
    "text": "Liwc is the main class for interacting with the LIWC CLI.\nliwc = Liwc(liwc_cli_path='LIWC-22-cli', threads=None, verbose=True) \nParameters: - liwc_cli_path (str): Path to the LIWC CLI executable. Default is ‘LIWC-22-cli’. On WSL, it is required to add .exe at the end ‘LIWC-22-cli.exe’, - threads (int, optional): Number of threads to use. Defaults to the number of CPU cores minus one. - verbose (bool, optional): If True, display printing such as progress bar for large files. Defaults to False.\nThe main Class of Pyliwc is Liwc.\n\nNote: Pyliwc requires that the LIWC-22 application is running on your computer. Please ensure that you currently have a copy of the LIWC-22 user interface open.",
    "crumbs": [
      "How to use"
    ]
  },
  {
    "objectID": "how-to-use.html#initialization",
    "href": "how-to-use.html#initialization",
    "title": "How to use",
    "section": "",
    "text": "Liwc is the main class for interacting with the LIWC CLI.\nliwc = Liwc(liwc_cli_path='LIWC-22-cli', threads=None, verbose=True) \nParameters: - liwc_cli_path (str): Path to the LIWC CLI executable. Default is ‘LIWC-22-cli’. On WSL, it is required to add .exe at the end ‘LIWC-22-cli.exe’, - threads (int, optional): Number of threads to use. Defaults to the number of CPU cores minus one. - verbose (bool, optional): If True, display printing such as progress bar for large files. Defaults to False.\nThe main Class of Pyliwc is Liwc.\n\nNote: Pyliwc requires that the LIWC-22 application is running on your computer. Please ensure that you currently have a copy of the LIWC-22 user interface open.",
    "crumbs": [
      "How to use"
    ]
  },
  {
    "objectID": "how-to-use.html#methods",
    "href": "how-to-use.html#methods",
    "title": "How to use",
    "section": "Methods",
    "text": "Methods\n\nLIWC analyze\nanalyze_df\nAnalyze text data from a Pandas DataFrame using LIWC.\n\nfrom pyliwc import Liwc\n\nliwc = Liwc('LIWC-22-cli.exe')\n\n\nresult_df = liwc.analyze_df(text_df, return_input=False, liwc_dict='LIWC22')\nExample\nimport pandas as pd\ndata = {'Text': [\"I am happy\", \"I feel sad today\"]}\ndf = pd.DataFrame(data)\nresult_df = liwc.analyze_df(df.Text)\nanalyze_csv\nAnalyze text data from a CSV file using LIWC.\nliwc.analyze_csv(input_file, output_location, row_id_indices, column_indices, liwc_dict='LIWC22')\nExample\nliwc.analyze_csv(\"input.csv\", \"output.csv\", \"0\", \"1\")\nanalyze_folder\nAnalyze all text files in a specified folder using LIWC.\nliwc.analyze_folder(input_folder, output_location, liwc_dict='LIWC22')\nExample\nliwc.analyze_folder('D:/Downloads/texts_folder', 'D:/Downloads')\nanalyze_string\nAnalyze a single string using LIWC.\nliwc.analyze_string(input_string, output_location, liwc_dict='LIWC22')\nExample\nliwc.analyze_string(\"I am feeling great\", \"D:/Downloads\")\nanalyze_string_to_json\nAnalyze a single string and return the result as a JSON object.\nliwc.analyze_string_to_json(input_string, liwc_dict='LIWC22')\nExample\nresult = liwc.analyze_string_to_json(\"This is an example string\")\nprint(result)\n\n{'Segment': 1, 'WC': 5, 'Analytic': 39.7, 'Clout': 40.06, 'Authentic': 1, 'Tone': 20.23, 'WPS': 5, 'BigWords': 20, 'Dic': 60, 'Linguistic': 60, 'function': 60, 'pronoun': 20, 'ppron': 0, 'i': 0, 'we': 0, 'you': 0, 'shehe': 0, 'they': 0, 'ipron': 20, 'det': 40, 'article': 20, 'number': 0, 'prep': 0, 'auxverb': 20, 'adverb': 0, 'conj': 0, 'negate': 0, 'verb': 20, 'adj': 0, 'quantity': 0, 'Drives': 0, 'affiliation': 0, 'achieve': 0, 'power': 0, 'Cognition': 0, 'allnone': 0, 'cogproc': 0, 'insight': 0, 'cause': 0, 'discrep': 0, 'tentat': 0, 'certitude': 0, 'differ': 0, 'memory': 0, 'Affect': 0, 'tone_pos': 0, 'tone_neg': 0, 'emotion': 0, 'emo_pos': 0, 'emo_neg': 0, 'emo_anx': 0, 'emo_anger': 0, 'emo_sad': 0, 'swear': 0, 'Social': 0, 'socbehav': 0, 'prosocial': 0, 'polite': 0, 'conflict': 0, 'moral': 0, 'comm': 0, 'socrefs': 0, 'family': 0, 'friend': 0, 'female': 0, 'male': 0, 'Culture': 0, 'politic': 0, 'ethnicity': 0, 'tech': 0, 'Lifestyle': 0, 'leisure': 0, 'home': 0, 'work': 0, 'money': 0, 'relig': 0, 'Physical': 0, 'health': 0, 'illness': 0, 'wellness': 0, 'mental': 0, 'substances': 0, 'sexual': 0, 'food': 0, 'death': 0, 'need': 0, 'want': 0, 'acquire': 0, 'lack': 0, 'fulfill': 0, 'fatigue': 0, 'reward': 0, 'risk': 0, 'curiosity': 0, 'allure': 0, 'Perception': 0, 'attention': 0, 'motion': 0, 'space': 0, 'visual': 0, 'auditory': 0, 'feeling': 0, 'time': 0, 'focuspast': 0, 'focuspresent': 20, 'focusfuture': 0, 'Conversation': 0, 'netspeak': 0, 'assent': 0, 'nonflu': 0, 'filler': 0, 'AllPunc': 0, 'Period': 0, 'Comma': 0, 'QMark': 0, 'Exclam': 0, 'Apostro': 0, 'OtherP': 0, 'Emoji': 0}\n\n\nLanguage Style Matching\nThis method allows the analysis of linguistic style matching, focusing on person and group-level analysis.\nanalyze_lsm\nPerform LSM analysis on a DataFrame.\n\nliwc.analyze_lsm(df, calculate_lsm='person-and-group', group_column='GroupID', person_column='PersonID', text_column='Text', output_type='pairwise', expanded_output=False, omit_speakers_number_of_turns=0, omit_speakers_word_count=10, segmentation='none')\nExample\nliwc = Liwc('LIWC-22-cli.exe')\nimport pandas as pd\n\n# Example DataFrame\ndata = {\n    'GroupID': [1, 1, 2, 2],\n    'PersonID': [101, 102, 201, 202],\n    'Text': [\"I like apples\",\n             \"He enjoys oranges\",\n             \"They eat bananas\",\n             \"We love grapes\"]\n}\ndf = pd.DataFrame(data)\n\nlsm_result = liwc.analyze_lsm(df,\n                              calculate_lsm=\"pairwise\",  \n                              person_column='PersonID',\n                              group_column='GroupID',\n                              text_column='Text',\n                              omit_speakers_word_count=1)\n# Group level\nlsm_result['group_level']\n\n\n\n\n\n\n\n\n\n\nGroupID\n\n\n\nSegment\n\n\n\nLSM\n\n\n\nWC.Total\n\n\n\n\n\n\n\n\n\n\n\n0\n\n\n\n1\n\n\n\n1\n\n\n\n0.88\n\n\n\n6\n\n\n\n\n\n\n\n1\n\n\n\n2\n\n\n\n1\n\n\n\n1.00\n\n\n\n6\n\n\n\n\n\n\n\n# Person level\nlsm_result['person_level']\n\n\n\n\n\n\n\n\n\n\nGroupID\n\n\n\nSegment\n\n\n\nPerson.1\n\n\n\nPerson.2\n\n\n\nLSM\n\n\n\nWC.Person.1\n\n\n\nWC.Person.2\n\n\n\n\n\n\n\n\n\n\n\n0\n\n\n\n1\n\n\n\n1\n\n\n\n101\n\n\n\n102\n\n\n\n0.88\n\n\n\n3\n\n\n\n3\n\n\n\n\n\n\n\n1\n\n\n\n2\n\n\n\n1\n\n\n\n201\n\n\n\n202\n\n\n\n1.00\n\n\n\n3\n\n\n\n3\n\n\n\n\n\n\n\n\n\nNarrative arc\nThe Narrative Arc Analysis feature provides insights into the narrative structure of texts by breaking them down into key components such as Staging, Plot Progression, and Cognitive Tension. This is particularly useful for understanding the flow and development of stories or articles. Here’s a closer look at how it works:\nHow It Works\n\nText Segmentation:\n\nThe text is divided into multiple segments, and each segment is analyzed separately.\nYou can control the number of segments using the segments_number parameter.\n\nComponents Analysis:\n\nStaging: This measures how much information is being set up at various points in the text.\nPlot Progression: This reflects the movement and development of the narrative.\nCognitive Tension: This captures the emotional or psychological tension present in the text.\n\nScaling Methods: Two scaling methods are available:\n\n0-100: Values are scaled between 0 and 100 for easy comparison.\nZ-score: Standardizes scores based on mean and standard deviation.\n\nOutput Options:\n\nChoose whether to output individual data points for each segment or aggregate the data.\nFilter out texts with word counts below a specified threshold using skip_wc. Function Usage\n\n\nHere is a breakdown of the narrative_arc function, which conducts the analysis:\nnarrative_arc\n\n\n\nnarrative_arc(\n    df=df, \n    column_names=['Text'], \n    output_individual_data_points=True, \n    scaling_method='0-100', \n    segments_number=5, \n    skip_wc=10\n)\nExample\n\nfrom pyliwc import Liwc\nimport pandas as pd\n\nliwc = Liwc('LIWC-22-cli.exe')\n\ndf = pd.DataFrame({\n    'Text': [\"\"\"\nOnce upon a time, in a land far away, there lived a young prince named Elior who was born without the ability to speak. One day, a wise inventor arrived at the castle with an AI device that could translate thoughts into speech. The prince accepted the device and, to everyone's amazement, his unspoken words became a beautiful voice. The entire kingdom rejoiced as Elior expressed his wisdom and compassion. With the power of AI, he not only found his voice but also united his people. Thus, the prince and his kingdom thrived, forever grateful for the miracle of technology.\"\"\"\n    ]\n})\n\n\nnarrative_results = liwc_analyzer.narrative_arc(\n    df=df, \n    column_names=['Text'], \n    output_individual_data_points=True, \n    scaling_method='0-100', \n    segments_number=5, \n    skip_wc=10\n)\n\nnarrative_results\n\n\n\n\n\n\n\n\n\n\nRow ID\n\n\n\nWC\n\n\n\nNarrativity_Overall\n\n\n\nNarrativity_Staging\n\n\n\nNarrativity_PlotProg\n\n\n\nNarrativity_CogTension\n\n\n\n\n\n\n\n\n\n\n\n0\n\n\n\n1\n\n\n\n100\n\n\n\n47.6\n\n\n\n81.09\n\n\n\n16.17\n\n\n\n45.54\n\n\n\n\n\n\n\n\nliwc = Liwc('LIWC-22-cli.exe')\n\ndf = pd.DataFrame({\n    'Text': [\"\"\"\nOnce upon a time, in a land far away, there lived a young prince named Elior who was born without the ability to speak. One day, a wise inventor arrived at the castle with an AI device that could translate thoughts into speech. The prince accepted the device and, to everyone's amazement, his unspoken words became a beautiful voice. The entire kingdom rejoiced as Elior expressed his wisdom and compassion. With the power of AI, he not only found his voice but also united his people. Thus, the prince and his kingdom thrived, forever grateful for the miracle of technology.\"\"\"\n    ]\n})\n\n\nnarrative_results = liwc.narrative_arc(\n    df=df, \n    column_names=['Text'], \n    output_individual_data_points=True, \n    scaling_method='0-100', \n    segments_number=5, \n    skip_wc=10\n)\n\n\nPlotting the Narrative Arc\nTo visually represent the narrative arc, you can use the plot_narrative_arc method:\nNote: output_individual_data_points must be set to True in narrative_arc to plot the results\n\nfrom pyliwc import Liwc\nimport pandas as pd\n\nliwc = Liwc('LIWC-22-cli.exe')\n\ndf = pd.DataFrame({\n    'Text': [\"\"\"\nOnce upon a time, in a land far away, there lived a young prince named Carlo who was born without the ability to speak.\nOne day, a wise inventor arrived at the castle with an AI device that could translate thoughts into speech. \nThe prince accepted the device and, to everyone's amazement, his unspoken words became a beautiful voice. \nThe entire kingdom rejoiced as Elior expressed his wisdom and compassion.\nWith the power of AI, he not only found his voice but also united his people. \nThus, the prince and his kingdom thrived, forever grateful for the miracle of technology.\"\"\"\n    ]\n})\n\n\nnarrative_results = liwc.narrative_arc(\n    df=df, \n    column_names=['Text'], \n    output_individual_data_points=True, \n    scaling_method='0-100', \n    skip_wc=10\n)\n\n#  Plot the Narrative Arc\n\nfig = liwc.plot_narrative_arc(narrative_results)\nfig",
    "crumbs": [
      "How to use"
    ]
  },
  {
    "objectID": "tutorial2_custom_dictionaries.html",
    "href": "tutorial2_custom_dictionaries.html",
    "title": "Text Analysis using custom dictionaries",
    "section": "",
    "text": "The pyliwc package is a powerful tool for text analysis using the LIWC framework. It helps in quantifying various linguistic and psychological features from text data, making it invaluable for researchers and data scientists interested in text analytics.\nIn this tutorial, we will focus on analyzing a simple string. The goal is to gain insights into their linguistic styles and psychological attributes as expressed in their speeches using custom dictionnaries.\n\nInternal Dictionnaries\nThe default internal dictionaries available are:\n\n\n\n\n\n\n\n\nDictionary\nLanguage\nParameter Value in liwc_dict\n\n\n\n\nLIWC-22 Dictionary\nEnglish\nLIWC22\n\n\nLIWC2015 Dictionary\nEnglish\nLIWC2015\n\n\nLIWC2007 Dictionary\nEnglish\nLIWC2007\n\n\nLIWC2001 Dictionary\nEnglish\nLIWC2001\n\n\nDE-LIWC2015 Dictionary\nGerman\nDE-LIWC2015\n\n\nLIWC2015 Dictionary - Chinese (Simplified) (v1.5)\nChinese (Simplified)\nCHNSIMPLLIWC2015\n\n\nLIWC2015 Dictionary - Chinese (Traditional) (v1.5)\nChinese (Traditional)\nCHNTRADLIWC2015\n\n\nMR-LIWC2015 Dictionary\nMarathi\nMRLIWC2015\n\n\nES-LIWC2007\nSpanish\nESLIWC2007\n\n\nJ-LIWC2015 Dictionary\nJapanese\nJLIWC2015\n\n\n\n*LIWC22 is the default option\n\nfrom pyliwc import Liwc\n\n# Initialize the Liwc instance with the LIWC CLI executable\nliwc = Liwc('LIWC-22-cli.exe')\n\ntext = \"On this day, we gather because we have chosen hope over fear, unity of purpose over conflict and discord.\"\n\nr = liwc.analyze_string_to_json(text, liwc_dict='LIWC2015')\nprint(r)\n\nPicked up JAVA_TOOL_OPTIONS: -Dfile.encoding=UTF-8\n\n\n{'Segment': 1, 'WC': 19, 'Analytic': 77.17, 'Clout': 99, 'Authentic': 19.27, 'Tone': 25.77, 'WPS': 19, 'Sixltr': 21.05, 'Dic': 78.95, 'function': 52.63, 'pronoun': 15.79, 'ppron': 10.53, 'i': 0, 'we': 10.53, 'you': 0, 'shehe': 0, 'they': 0, 'ipron': 5.26, 'article': 0, 'prep': 21.05, 'auxverb': 5.26, 'adverb': 0, 'conj': 10.53, 'negate': 0, 'verb': 10.53, 'adj': 0, 'compare': 0, 'interrog': 0, 'number': 0, 'quant': 0, 'affect': 10.53, 'posemo': 5.26, 'negemo': 5.26, 'anx': 5.26, 'anger': 0, 'sad': 0, 'social': 15.79, 'family': 0, 'friend': 0, 'female': 0, 'male': 0, 'cogproc': 15.79, 'insight': 0, 'cause': 10.53, 'discrep': 5.26, 'tentat': 5.26, 'certain': 0, 'differ': 0, 'percept': 0, 'see': 0, 'hear': 0, 'feel': 0, 'bio': 0, 'body': 0, 'health': 0, 'sexual': 0, 'ingest': 0, 'drives': 31.58, 'affiliation': 15.79, 'achieve': 5.26, 'power': 10.53, 'reward': 0, 'risk': 0, 'focuspast': 0, 'focuspresent': 10.53, 'focusfuture': 5.26, 'relativ': 21.05, 'motion': 0, 'space': 15.79, 'time': 5.26, 'work': 0, 'leisure': 0, 'home': 0, 'money': 0, 'relig': 0, 'death': 0, 'informal': 0, 'swear': 0, 'netspeak': 0, 'assent': 0, 'nonflu': 0, 'filler': 0, 'AllPunc': 15.79, 'Period': 5.26, 'Comma': 10.53, 'Colon': 0, 'SemiC': 0, 'QMark': 0, 'Exclam': 0, 'Dash': 0, 'Quote': 0, 'Apostro': 0, 'Parenth': 0, 'OtherP': 0, 'Emoji': 0}\n\n\n\n\nUser-Created LIWC Dictionaries\nIf you would like to analyze your text with an external dictionary file, you may alternatively provide the path to your dictionary.\nVisit liwc.app/dictionaries to download a user-created dictionnary.\nHere is an example to measure the 10 Schwartz Values (and 4 higher-order value dimensions) using the dictionary developed by Ponizovskiy et al. (2020). &gt; Ponizovskiy, V., Ardag, M., Grigoryan, L., Boyd, R., Dobewall, H., & Holtz, P. (2020). Development and validation of the Personal Values Dictionary: A theory-driven tool for investigating references to basic human values in text. European Journal of Personality, 34(5), 885–902. https://doi.org/10.1002/per.2294\nfrom pyliwc import Liwc\n\n# Initialize the Liwc instance with the LIWC CLI executable\n\n\nliwc = Liwc('LIWC-22-cli.exe')\n\ntext = \"On this day, we gather because we have chosen hope over fear, unity of purpose over conflict and discord.\"\n\nr = liwc.analyze_string_to_json(text, liwc_dict='dictionaries/stereotype-content-dictionary.dicx')\nprint(r)\nSegment                       1.00\nWC                           19.00\nWPS                          19.00\nBigWords                     21.05\nDic                          26.32\nValence_Pos                   3.00\nValence_Neg                   4.11\nValence_Neut                 19.21\nSociability_Freq              0.00\nSociability_Direction         0.00\nMorality_Freq               526.32\nMorality_Direction           -5.26\nAbility_Freq                  0.00\nAbility_Direction             0.00\nAgency_Freq                1052.63\nAgency_Direction              0.00\nHealth_Freq                 526.32\nHealth_Direction             -5.26\nStatus_Freq                   0.00\nStatus_Direction              0.00\nWork_Freq                     0.00\nWork_Direction                0.00\nPolitics_Freq                 0.00\nPolitics_Direction            0.00\nReligion_Freq                 0.00\nReligion_Direction            0.00\nBeliefs_Other_Freq            0.00\nBeliefs_Other_Direction       0.00\nInhabitant_Freq               0.00\nCountry_Freq                  0.00\nFeelings_Freq              1052.63\nRelatives_Freq                0.00\nClothing_Freq                 0.00\nOrdinariness_Freq             0.00\nOrdinariness_Direction        0.00\nBody_Part_Freq                0.00\nBody_Property_Freq            0.00\nSkin_Freq                     0.00\nBody_Covering_Freq            0.00\nBeauty_Freq                   0.00\nBeauty_Direction              0.00\nInsults_Freq                  0.00\nSTEM_Freq                     0.00\nHumanities_Freq               0.00\nArt_Freq                      0.00\nSocial_Groups_Freq            0.00\nLacks_Knowledge_Freq          0.00\nFortune_Freq                  0.00\nAllPunc                      15.79\nPeriod                        5.26\nComma                        10.53\nQMark                         0.00\nExclam                        0.00\nApostro                       0.00\nOtherP                        0.00\nEmoji                         0.00\n\n\nOther Dictionaries Available\n\n\n\n\n\n\n\n\n\nDictionary Name\nDescription\nAuthor\nUploaded\n\n\n\n\nAbsolutist Dictionary\nMeasures absolutist thinking (e.g., always, never) in texts\nAl-Mosaiwi & Johnstone\n2022-01-01\n\n\nAge Stereotypes Dictionary\nReflects eight broadly-defined stereotypes identified in past research as descriptive of older adults\nJessica Remedios\n2022-01-01\n\n\nAgitation/Dejection Dictionary\nBased on studies linking promotion versus prevention focus with the emotions “Agitation” and “Dejection”\nJohnsen et al.\n2022-01-01\n\n\nAI Focus Dictionary\n122 AI-related words for measuring a company’s focus on AI\nMishra, Ewing, & Cooper\n2024-03-14\n\n\nAmerican Indian Stereotype Dictionary\nA custom dictionary to find the prevalence of words associated with American Indian stereotypes and conventional narratives\nAleksandra Sherman\n2022-01-01\n\n\nanticoagulation\nWords associated with anticoagulation therapy - primarily nouns added to supplement existing dictionaries\nPeter Whittaker\n2023-02-11\n\n\nBehavioral Activation Dictionary\nCaptures linguistic indicators of planning and participation in enjoyable activities\nBurkhardt et al.\n2022-01-01\n\n\nBig Two (Agency & Communion) Dictionary\nMeasure the degree to which a person is thinking in terms of agency/communion.\nPietraszkiewicz et al.\n2022-01-01\n\n\nBody Type Dictionary\nA content analysis dictionary for automating the scoring of Fisher & Cleveland’s (1958) body type framework in English-language texts.\nAndrew Wilson\n2022-01-01\n\n\nBrand Personality Dictionary\nAssesses Aaker’s five brand personality dimensions as well as 42 personality trait norms\nOpoku et al.\n2022-01-01\n\n\nClimate Change Dictionary\nDictionary used to quantify mentions of climate change in online discussion\nMiti Shah\n2023-05-23\n\n\nControversial Terms Lexicon\nA lexicon of terms that range in their degree of controversiality, particularly in terms of their use in the media.\nMejova et al.\n2022-01-01\n\n\nCorporate Social Responsibility Dictionary\nReveals four dimensions of corporate social responsibility\nNadra Pencle & Irina Mălăescu\n2022-01-01\n\n\nCost/Benefit Dictionary\nMeasures language related to perceived costs and benefits that result from a decision or behavior.\nMichael McCullough\n2022-01-01\n\n\nCreativity and Innovation Dictionary\nLanguage describing creation and/or innovation\nNeufeld and Gaucher\n2022-01-01\n\n\nCrovitz Innovator Identification Method\nIdentify “innovators” and “non-innovators” using Hebert F. Crovitz’s 42 relational words\nGreco et al.\n2022-01-01\n\n\nDehumanization Dictionary\nMeasures several types of (de)humanization, such as mechanistic and animalistic dehumanization\nSamantha Platten\n2022-01-01\n\n\nDiccionario de polaridad y clase de palabras - Esp\nDiccionario de polaridad (+/-) por clases de palabras\nJavier Blasco-Pascual\n2022-09-13\n\n\nDigital Orientation Dimensions\nDigital orientation dimensions keyword classification based on the research of Kindermann et al. (2021)\nKonstantinos Emexidis\n2023-05-17\n\n\nEmpath Default Dictionary\nGeneral content-coding dictionary from the “Empath” package\nFast, Chen, & Bernstein\n2022-01-01\n\n\nEmpathic Concern Lexicon\nAn automatically created empathy dictionary extracted from document-level ratings\nJoão Sedoc\n2023-09-14\n\n\nEnglish Prime Dictionary\nCaptures violations of the English Prime system, a theoretical marker of cognitive inflexibility.\nRyan L. Boyd\n2022-01-01\n\n\nEnriched American Food Lexicon\nDictionary containing ~500 foods mapped to USDA categories, with some caloric information.\nAbbar et al.\n2022-01-01\n\n\nEntrepreneurial and Mentoring Dictionary\nA dictionary of entrepreneurial and mentoring terms\nSteven D’Alessandro and Morgan Miles\n2022-01-01\n\n\nextended Moral Foundations Dictionary (eMFD)\nThe eMFD, unlike previous methods, is constructed from text annotations generated by a large sample of human coders.\nHopp et al.\n2022-01-01\n\n\nForesight Lexicon\nMeasures the degree to which anticipation/foresight occurs. That is, words pointing to indicate where things are heading (often on the basis of recurrent behaviors).\nRobert Hogenraad\n2022-01-01\n\n\nForest Values Dictionary\nReflects four distinct ways in which people value forests and forest ecosystems\nBengston & Xu\n2022-01-01\n\n\nGeneral Inquirer IV\nThe “original” mainstream text analysis dictionary that is still used often today. Many categories are of questionable validity.\nPhilip Stone et al.\n2022-01-01\n\n\nGerman-Language STEM Dictionary\nUsed to measure communication about STEM (Science, Technology, Engineering, Mathematics).\nMichael Heilemann\n2022-01-01\n\n\nGlobal Citizen Dictionary\nA dictionary to assess language usage related to global citizenship\nStephen Reysen et al.\n2022-01-01\n\n\nGrant Evaluation Dictionary\nCaptures categories relevant to scientific grant review (ability, achievement, agentic, research, standout, pos eval, neg eval)\nKaatz et al.\n2022-01-01\n\n\nGrievance Dictionary\nA psycholinguistic dictionary that can be used to automatically understand language use in the context of grievance-fueled violence threat assessment\nIsabelle van der Vegt\n2022-01-01\n\n\nHome Perceptions Dictionary\nCalculates the frequency of words describing clutter, a sense of the home as unfinished, restful words, and nature words\nSaxbe & Repetti\n2022-01-01\n\n\nHonor Dictionary\nThis dictionary is designed to diagnose “honor talk” in any text that you are interested in analyzing.\nGelfand et al.\n2022-01-01\n\n\nImagination Lexicon\nDigital lexicon of 627 entries relative to imagination and transfiguration, i.e., words pointing to the unbelievable and whatever is beyond the real.\nRobert Hogenraad\n2022-01-01\n\n\nIncel Violent Extremism Dictionary\nThree types of words, including common words about violence, weapons, and some of the most recognizable incel terms\nBaele et al.\n2023-02-13\n\n\nInvective Dictionary\nUse this dictionary to detect invective language in narrative\nA. T. Panter\n2022-01-01\n\n\nLinguistic Category Model (LCM) Dictionary\nA computerized LCM analysis method\nYi-Tai Seih\n2022-01-01\n\n\nLIWC-UD: Urban Dictionary LIWC Supplements\nAn automatically generated extension to LIWC’s dictionary which includes terms defined in Urban Dictionary\nBahgat, Wilson, & Magdy\n2023-02-13\n\n\nLoughran-McDonald LM dic\nLoughran-McDonald\nLoughran-McDonald\n2023-09-14\n\n\nLoughran-McDonald financial sentiment\nTone dictionary\nLoughran-McDonald\n2023-03-07\n\n\nLoughran-McDonald Financial Sentiment Dictionary\nDictionary for measuring positive and negative sentiment specifically in financial texts.\nLoughran & McDonald\n2022-01-01\n\n\nMarcadoresDiscursivos - Español.dicx\nDiccionario nativo de partículas discursivas del español\nJavier Blasco-Pascual\n2022-08-25\n\n\nMasculine & Feminine Words\nList of masculine and feminine words from Gaucher et al. (2011)\nMaureen McCusker\n2022-01-01\n\n\nMindfulness Dictionary\nTwo categories of mindfulness language describing the mindfulness state and the more encompassing “mindfulness journey”\nCollins et al.\n2022-01-01\n\n\nMind Perception Dictionary\nMeasures linguistic use of mind perception (words related to “agency” and “experience”) in naturalistic settings\nSchweitzer & Waytz\n2022-01-01\n\n\nMoral Foundations Dictionary 2.0\nAn updated version of the Moral Foundations Dictionary that is recommended over the original by its creators.\nJeremy Frimer\n2022-01-01\n\n\nMoral Foundations Dictionary\nProvides information on the proportions of virtue and vice words for each foundation on whatever corpus of text you are interested in\nJesse Graham and Jonathan Haidt\n2022-01-01\n\n\nMorality-as-Cooperation Dictionary\nCodes for constructs from the “Morality-as-Cooperation” theory, originating from ethnographic accounts of morality\nMark Alfano, Marc Cheong, & Oliver Scott Curry\n2024-02-29\n\n\nMoral Justification Dictionary\nMeasures variation in justification content (deontological, consequentialist, or emotive) as a function of moral foundations\nWheeler & Laham\n2022-01-01\n\n\nMoral Universalism in French\nA set of terminologies associated with morally universal language, based on the English version of Graham et al.\nMichael Jetter & Akim Defesche\n2024-05-21\n\n\nMoral Universalism in German\nA set of terminologies associated with morally universal language, based on the English version of Graham et al.\nMichael Jetter\n2024-05-21\n\n\nMoral Universalism in Italian\nA set of terminologies associated with morally universal language, based on the English version of Graham et al.\nMichael Jetter & Marianna Piantavigna\n2024-05-21\n\n\nMoral Universalism in Spanish\nA set of terminologies associated with morally universal language\nMichael Jetter & Raquel Bra Nunez\n2024-05-01\n\n\nMotivated Social Cognition Dictionary\nMeasures the degree to which a person is thinking in a way that reflects various motivated social cognitions (e.g., uncertainty avoidance)\nJayme Renfro et al.\n2022-01-01\n\n\nMystical Language Dictionary\nA set of words that, when encountered in an experience report, indicate the occurrence of mystical elements within the experience.\nMarija Franka Žuljevića et al.\n2023-11-03\n\n\nNonconformity\nNonconformity\nPatti\n2024-03-12\n\n\nNostalgia Dictionary\nA 98-word dictionary that captures expressions of nostalgia in text.\nJia Chen\n2023-05-16\n\n\nOpen Science Dictionary\nThis is a validated dictionary that taps into open science categories (e.g., open science, preregistration, replication)\nDavid Markowitz\n2022-05-08\n\n\nPain Dictionary\nMeasures the language of pain disclosure. Made with special attention to previously validated pain scales\nWright et al.\n2022-01-01\n\n\nPersonal Values Dictionary\nMeasures the 10 Schwartz Values (and 4 higher-order value dimensions).\nPonizovskiy et al.\n2022-01-01\n\n\nPhysiological Sensations Dictionary\nMeasures the amount that a person is describing physical sensations (e.g., bloated, dizzy, faint).\nShaffer, Kim, & Yoon\n2022-01-01\n\n\nPolicy Position Dictionary\nProvides estimation of the policy position of political texts (e.g., transcribed speeches) in the United Kingdom\nLaver & Garry\n2022-01-01\n\n\nPornography Lexicon Dictionary\nThis lexicon is based on merging LIWC’s internal lexica of sexuality and drives (2015) with Essam’s lexicon of pornography (2017).\nEncarnacion S. Arenas\n2022-01-01\n\n\nPrivacy Dictionary\nContains a list of words that people use when talking about privacy. Organised into 8 categories that measure different dimensions of privacy\nVasalou et al.\n2022-01-01\n\n\npromotion\nPROMFOC\nGamache\n2023-11-06\n\n\nProrefugee Content Dictionary\nMeasures the proportion of words that contained prorefugee content within a text (rather than refugee content in general)\nSmith et al.\n2022-01-01\n\n\nProsocial Words Dictionary\nCalculates the density of prosocial words in anything that a person says\nJeremy Frimer\n2022-01-01\n\n\nQualia Dictionary\nWords referring to the five senses, broken down into types of qualia (e.g., for vision: colors, luminance, actions, and shapes).\nMolly Ireland et al.\n2022-01-01\n\n\nRegressive Imagery Dictionary\nDictionary designed to capture primary (i.e., primordial) and secondary (i.e., “conceptual”) processes from natural language.\nColin Martindale\n2022-01-01\n\n\nRegulatory Mode Dictionary\nLocomotion and Assessment States of Goal Pursuit\nDana Kanze, Mark A. Conley, and E. Tory Higgins\n2022-01-01\n\n\nRomantic Love Dictionary\nMeasures of “emotional investment” and “attraction” for historical assessment of romantic love\nMauricio de Jesus Dias Martins & Nicolas Baumard\n2023-12-27\n\n\nSecurity Language Dictionary\nProvides a reference for the comparative study of security-related linguistic repertoires in political texts (speeches, policy documents, etc.).\nStephane Baele & Olivier Sterck\n2022-01-01\n\n\nSelf-Care Dictionary\nMeasures the degree to which self-care words are used (e.g., diet, yoga)\nXunyi Wang et al.\n2022-01-01\n\n\nSelf-Determination/Self-Talk Dictionary\nDesigned for use with self-talk data. Measures autonomy-supportive versus controlling language within self-talk.\nOliver et al.\n2022-01-01\n\n\nSelf-Transcendent Emotion Dictionary (STED)\nScores texts for emotions that are invaluable to promote greater human connectedness, prosociality, and human flourishing\nJi & Raney\n2022-01-01\n\n\nSituational 8 Dictionary (S8-LIWC)\nCaptures language that corresponds to each of the DIAMONDS dimensions of situations\nDavid G. Serfass\n2022-01-01\n\n\nSleep Dictionary\nA dictionary designed to capture sleep-related communications\nIlana Ladis\n2023-02-11\n\n\nSocial Ties Dictionary\nAssesses spontaneous indicators of important social relationships\nPressman & Cohen\n2022-01-01\n\n\nStereotype Content Dictionary\nA stereotype content dictionary, made using a semi-automated method, to capture the Stereotype Content Model in text\nNicolas et al.\n2022-01-01\n\n\nStress Dictionary\nA dictionary used to measure psychological stress. Created based on the LIWC2007 English Dictionary.\nWei Wang et al.\n2022-01-01\n\n\nThe Weighted Reflection-Reorganizing List\nCaptures reflection on the emotional significance of an event or events in one’s own or someone else’s life, or in a dream/fantasy.\nMurphy, Bucci, & Maskit\n2022-01-01\n\n\nThreat Dictionary\nThis dictionary was designed to diagnose threatening language in any text that interests you.\nVirginia K. Choi et al.\n2022-02-23\n\n\nTransactive Memory Systems (TMS) Strength\nThis dictionary provides a measure of the positive and negative indicators of TMS from group conversational text.\nJonathan Kush, Brandy Aven, Linda Argote\n2023-08-10\n\n\nWater Metaphor Dictionary\nMeasures the frequency of inundation-metaphoric expressions as it relates to immigration.\nTyler Jimenez\n2022-01-01\n\n\nWeighted Referential Activity Dictionary\nYields a Referential Activity (RA) score for any natural language segment.\nBucci & Maskit\n2022-01-01\n\n\nWell-being Dictionary\nWords that might indicate the presence of purpose or meaning\nRatner et al.\n2022-01-01\n\n\nWhirlall Dictionary\nMeasures words related to “whirling” and “twirling” in Rorschach responses\nRyan L. Boyd\n2022-01-01",
    "crumbs": [
      "Tutorials",
      "Text Analysis using custom dictionaries"
    ]
  },
  {
    "objectID": "quickstart.html",
    "href": "quickstart.html",
    "title": "Quickstart",
    "section": "",
    "text": "Here’s a quickstart guide, explaining how to use pyliwc perform text analysis.\nLiwc is the main class for interacting with the LIWC CLI.\nliwc = Liwc(liwc_cli_path='LIWC-22-cli', threads=None, verbose=True) \nParameters: - liwc_cli_path (str): Path to the LIWC CLI executable. Default is ‘LIWC-22-cli’. On WSL, it is required to add .exe at the end ‘LIWC-22-cli.exe’, - threads (int, optional): Number of threads to use. Defaults to the number of CPU cores minus one. - verbose (bool, optional): If True, display printing such as progress bar for large files. Defaults to False.\nThe main Class of Pyliwc is Liwc.\n\nNote: Make sure that you have LIWC-22 software running on your computer — it is required for using all methods\n\n\n\nAnalyze a string using the default dictionary (LIWC22)\n\nfrom pyliwc import Liwc\n\nliwc = Liwc('LIWC-22-cli.exe')\n\ntext = \"This is a sample text for LIWC analysis.\"\n\nr = liwc.analyze_string_to_json(text)\n\nPicked up JAVA_TOOL_OPTIONS: -Dfile.encoding=UTF-8\n\n\n{\n    'Segment': 1,\n    'WC': 8,\n    'Analytic': 89.52,\n    'Clout': 40.06,\n    'Authentic': 15.38,\n    'Tone': 20.23,\n    'WPS': 8,\n    'BigWords': 12.5,\n    'Dic': 100,\n    'Linguistic': 62.5,\n    'function': 50,\n    'pronoun': 12.5,\n    'ppron': 0,\n    'i': 0,\n    'we': 0,\n    'you': 0,\n    ... ,\n    'AllPunc': 12.5,\n    'Period': 12.5,\n    'Comma': 0,\n    'QMark': 0,\n    'Exclam': 0,\n    'Apostro': 0,\n    'OtherP': 0,\n    'Emoji': 0\n}\n\nAnalyzing Texts from a pandas DataFrame\n\nimport pandas as pd\ndf = pd.read_csv('../data/US-president.csv')\n\n\nfrom pyliwc import Liwc\n\nliwc = Liwc('LIWC-22-cli.exe')\n\nliwc.analyze_df(df.Text, liwc_dict=\"LIWC22\")\n\n\n\n\n\n\n\n\nSegment\nWC\nAnalytic\nClout\nAuthentic\nTone\nWPS\nBigWords\nDic\nLinguistic\n...\nnonflu\nfiller\nAllPunc\nPeriod\nComma\nQMark\nExclam\nApostro\nOtherP\nEmoji\n\n\nRow ID\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n0\n1\n1592\n52.22\n93.17\n34.71\n79.12\n16.58\n22.49\n91.21\n66.46\n...\n0\n0\n14.20\n5.97\n6.53\n0.06\n0\n0.63\n1.01\n0\n\n\n1\n1\n2389\n51.22\n95.37\n36.07\n54.01\n20.25\n19.21\n90.37\n68.48\n...\n0\n0\n12.98\n5.11\n6.20\n0.00\n0\n0.54\n1.13\n0\n\n\n2\n1\n1457\n46.94\n98.19\n42.58\n82.46\n16.19\n21.89\n91.08\n66.78\n...\n0\n0\n15.31\n6.18\n7.28\n0.00\n0\n0.75\n1.10\n0\n\n\n3\n1\n2548\n43.37\n91.33\n50.66\n45.63\n15.35\n17.39\n93.21\n71.15\n...\n0\n0\n19.66\n6.28\n9.11\n0.39\n0\n1.69\n2.20\n0\n\n\n\n\n4 rows × 119 columns\n\n\n\n\nChange to other dictionary: “LIWC2015”\n\n\nliwc_dict = \"LIWC2015\" \n\nliwc.analyze_df(df.Text, liwc_dict=liwc_dict)\n\n\n\n\n\n\n\n\nSegment\nWC\nAnalytic\nClout\nAuthentic\nTone\nWPS\nSixltr\nDic\nfunction\n...\nColon\nSemiC\nQMark\nExclam\nDash\nQuote\nApostro\nParenth\nOtherP\nEmoji\n\n\nRow ID\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n0\n1\n1592\n65.12\n92.38\n30.27\n89.13\n16.58\n22.49\n89.38\n53.33\n...\n0.38\n0.38\n0.06\n0\n0.00\n0.25\n0.63\n0\n0.00\n0\n\n\n1\n1\n2389\n64.97\n93.13\n33.34\n74.15\n20.25\n19.21\n87.57\n55.04\n...\n0.13\n0.21\n0.00\n0\n0.63\n0.08\n0.54\n0\n0.08\n0\n\n\n2\n1\n1457\n57.63\n96.73\n40.07\n87.87\n16.19\n21.89\n87.99\n53.12\n...\n0.55\n0.34\n0.00\n0\n0.07\n0.14\n0.75\n0\n0.00\n0\n\n\n3\n1\n2548\n58.30\n91.76\n44.26\n62.24\n15.35\n17.39\n90.07\n55.42\n...\n0.90\n0.39\n0.39\n0\n0.16\n0.63\n1.69\n0\n0.12\n0\n\n\n\n\n4 rows × 95 columns",
    "crumbs": [
      "Quickstart"
    ]
  },
  {
    "objectID": "license.html",
    "href": "license.html",
    "title": "License",
    "section": "",
    "text": "MIT License\nPermission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the “Software”), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions:\nThe above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.\nTHE SOFTWARE IS PROVIDED “AS IS”, WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.",
    "crumbs": [
      "License"
    ]
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "Written by Camille Lacan.",
    "crumbs": [
      "About"
    ]
  },
  {
    "objectID": "readme.html",
    "href": "readme.html",
    "title": "Welcome to pyliwc",
    "section": "",
    "text": "CI\n\n\n\nOverview\nPyLIWC is a Python package designed to provide an interface for analyzing text using the LIWC (Linguistic Inquiry and Word Count) tool. This package allows users to interact with the LIWC CLI from within Python, offering features for processing various data formats, performing linguistic style matching, and analyzing narrative arcs in text data. It can handle folders, text files or Pandas dataframes.\nAs the LIWC dictionary is proprietary software, this requires that you have installed the latest version of the LIWC software on your machine, with an activated licence (academic licence).\n\n\nManifest\nThe LIWC (Linguistic Inquiry and Word Count) software by James W. Pennebaker, Roger J. Booth, and Martha E. Francis has been instrumental for countless researchers in analyzing linguistic and psycholinguistic data. Linguistic Inquiry and Word Count (LIWC) is the gold standard of dictionary-based approaches for analyzing word use. It can be used to study a single individual, groups of people over time, or all of social media.However, LIWC has traditionally been available through software, necessitating the usage of an outside software to the Python environement.\nRecognizing the growing popularity of Python in the scientific and research community, there is an important need for researchers and data scientists for integrating LIWC directly into their Python workflows. Thus, pyliwc brings (many of) the functionality of LIWC to a wider audience without the need use the LIWC application as GUI. pyliwc is open-source, released under the MIT license, and is designed to enable researchers to perform sophisticated linguistic analysis directly in Python.\n\n\nFeatures\nThe package offers a wide range of features, including:\n\nLIWC Text Analysis:\n\n\nAnalyze text data from various sources, including CSV files, directories, Pandas DataFrames, and individual strings.\nSupports internal dictionaries (e.g., LIWC22, LIWC2015) as well as adhoc dictionaries\nOutput results directly in a convenient Pandas DataFrame for easy integration with other data processing tools.\n\n\nLinguistic Style Matching (LSM):\n\n\nPerform person and group-level LSM analysis using a DataFrame to evaluate the alignment of linguistic styles in conversational data.\nSupports pairwise LSM calculations for detailed analysis of interpersonal communication dynamics.\n\n\nNarrative Arc Analysis:\n\n\nAnalyze the narrative arc of text data to understand staging, progression, and cognitive tension, offering deep insights into storytelling elements.\nGraphics capabilities are included, allowing users to visualize narrative structures: staging, plot progression, and cognitive tension over time.\nProvides customizable scaling methods and segment options for precise control over the analysis process.\n\n\nIntegration with LIWC CLI: Seamlessly execute LIWC commands and capture output for further processing, leveraging the full power of LIWC’s linguistic analysis capabilities. Multithreading support for improved performance and faster analysis across large datasets.\nOutput Options: Flexible output formats, including CSV, JSON, and direct integration with Pandas DataFrames, ensuring compatibility with a wide range of data analysis workflows.\n\n\nMissing Features: In the current version, the following features have not yet been ported : Word frequencies, Meaning extraction and Contextualizer.\n\n\nInstallation\nYou can install pyliwc via pip in Python.\nRequirements : * Python 3.6 or above * LIWC software\nUsing pip\npip install pyliwc\n\n\nQuickstart\nHere’s a quickstart guide, explaining how to use pyliwc perform text analysis.\nLiwc is the main class for interacting with the LIWC CLI.\nliwc = Liwc(liwc_cli_path='LIWC-22-cli', threads=None, verbose=True) \nParameters: - liwc_cli_path (str): Path to the LIWC CLI executable. Default is ‘LIWC-22-cli’. On WSL, it is required to add .exe at the end ‘LIWC-22-cli.exe’, - threads (int, optional): Number of threads to use. Defaults to the number of CPU cores minus one. - verbose (bool, optional): If True, display printing such as progress bar for large files. Defaults to False.\nThe main Class of Pyliwc is Liwc.\n\nNote: Make sure that you have LIWC-22 software running on your computer — it is required for using all methods\n\n\n\nAnalyze a string using the default dictionary (LIWC22)\n\nfrom pyliwc import Liwc\n\nliwc = Liwc('LIWC-22-cli.exe')\n\ntext = \"This is a sample text for LIWC analysis.\"\n\nr = liwc.analyze_string_to_json(text)\n\nPicked up JAVA_TOOL_OPTIONS: -Dfile.encoding=UTF-8\n\n\n{\n    'Segment': 1,\n    'WC': 8,\n    'Analytic': 89.52,\n    'Clout': 40.06,\n    'Authentic': 15.38,\n    'Tone': 20.23,\n    'WPS': 8,\n    'BigWords': 12.5,\n    'Dic': 100,\n    'Linguistic': 62.5,\n    'function': 50,\n    'pronoun': 12.5,\n    'ppron': 0,\n    'i': 0,\n    'we': 0,\n    'you': 0,\n    ... ,\n    'AllPunc': 12.5,\n    'Period': 12.5,\n    'Comma': 0,\n    'QMark': 0,\n    'Exclam': 0,\n    'Apostro': 0,\n    'OtherP': 0,\n    'Emoji': 0\n}\n\nAnalyzing Texts from a pandas DataFrame\n\nimport pandas as pd\ndf = pd.read_csv('../data/US-president.csv')\n\n\nfrom pyliwc import Liwc\n\nliwc = Liwc('LIWC-22-cli.exe')\n\nliwc.analyze_df(df.Text, liwc_dict=\"LIWC22\")\n\n\n\n\n\n\n\n\nSegment\nWC\nAnalytic\nClout\nAuthentic\nTone\nWPS\nBigWords\nDic\nLinguistic\n...\nnonflu\nfiller\nAllPunc\nPeriod\nComma\nQMark\nExclam\nApostro\nOtherP\nEmoji\n\n\nRow ID\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n0\n1\n1592\n52.22\n93.17\n34.71\n79.12\n16.58\n22.49\n91.21\n66.46\n...\n0\n0\n14.20\n5.97\n6.53\n0.06\n0\n0.63\n1.01\n0\n\n\n1\n1\n2389\n51.22\n95.37\n36.07\n54.01\n20.25\n19.21\n90.37\n68.48\n...\n0\n0\n12.98\n5.11\n6.20\n0.00\n0\n0.54\n1.13\n0\n\n\n2\n1\n1457\n46.94\n98.19\n42.58\n82.46\n16.19\n21.89\n91.08\n66.78\n...\n0\n0\n15.31\n6.18\n7.28\n0.00\n0\n0.75\n1.10\n0\n\n\n3\n1\n2548\n43.37\n91.33\n50.66\n45.63\n15.35\n17.39\n93.21\n71.15\n...\n0\n0\n19.66\n6.28\n9.11\n0.39\n0\n1.69\n2.20\n0\n\n\n\n\n4 rows × 119 columns\n\n\n\n\nChange to other dictionary: “LIWC2015”\n\n\nliwc_dict = \"LIWC2015\" \n\nliwc.analyze_df(df.Text, liwc_dict=liwc_dict)\n\n\n\n\n\n\n\n\nSegment\nWC\nAnalytic\nClout\nAuthentic\nTone\nWPS\nSixltr\nDic\nfunction\n...\nColon\nSemiC\nQMark\nExclam\nDash\nQuote\nApostro\nParenth\nOtherP\nEmoji\n\n\nRow ID\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n0\n1\n1592\n65.12\n92.38\n30.27\n89.13\n16.58\n22.49\n89.38\n53.33\n...\n0.38\n0.38\n0.06\n0\n0.00\n0.25\n0.63\n0\n0.00\n0\n\n\n1\n1\n2389\n64.97\n93.13\n33.34\n74.15\n20.25\n19.21\n87.57\n55.04\n...\n0.13\n0.21\n0.00\n0\n0.63\n0.08\n0.54\n0\n0.08\n0\n\n\n2\n1\n1457\n57.63\n96.73\n40.07\n87.87\n16.19\n21.89\n87.99\n53.12\n...\n0.55\n0.34\n0.00\n0\n0.07\n0.14\n0.75\n0\n0.00\n0\n\n\n3\n1\n2548\n58.30\n91.76\n44.26\n62.24\n15.35\n17.39\n90.07\n55.42\n...\n0.90\n0.39\n0.39\n0\n0.16\n0.63\n1.69\n0\n0.12\n0\n\n\n\n\n4 rows × 95 columns"
  },
  {
    "objectID": "installation.html",
    "href": "installation.html",
    "title": "Installation",
    "section": "",
    "text": "You can install pyliwc via pip in Python.\nRequirements : * Python 3.6 or above * LIWC software\nUsing pip\npip install pyliwc",
    "crumbs": [
      "Installation"
    ]
  },
  {
    "objectID": "tutorial1_us_presidents.html",
    "href": "tutorial1_us_presidents.html",
    "title": "Text Analysis of U.S. Presidents’ Inaugural Addresses",
    "section": "",
    "text": "The pyliwc package is a powerful tool for text analysis using the LIWC framework. It helps in quantifying various linguistic and psychological features from text data, making it invaluable for researchers and data scientists interested in text analytics.\nIn this tutorial, we will focus on analyzing the inaugural addresses of four U.S. Presidents: George W. Bush, Barack Obama, Donald Trump, and Joe Biden. The goal is to gain insights into their linguistic styles and psychological attributes as expressed in their speeches.\n\n💻 Installation\nTo install the pyliwc package, you need to have Python and pip installed on your system. Use the following command to install:\npip install pyliwc\nOr using Conda\nconda install -c pyliwc\nEnsure that you have the LIWC-22-cli.exe executable available, as it is required for the analysis.\n\n\n🚀 Quick start\nTo begin using pyliwc, you need to import the Liwc class from the package and create an instance. Here’s how you can get started:\n\nfrom pyliwc import Liwc\n\n# Initialize the Liwc instance with the LIWC CLI executable\nliwc = Liwc('LIWC-22-cli.exe')\n\ntext = \"On this day, we gather because we have chosen hope over fear, unity of purpose over conflict and discord.\"\n\nr = liwc.analyze_string_to_json(text)\nprint(r)\n\nPicked up JAVA_TOOL_OPTIONS: -Dfile.encoding=UTF-8\n\n\n{'Segment': 1, 'WC': 19, 'Analytic': 67.62, 'Clout': 99, 'Authentic': 8.42, 'Tone': 1, 'WPS': 19, 'BigWords': 21.05, 'Dic': 89.47, 'Linguistic': 63.16, 'function': 52.63, 'pronoun': 15.79, 'ppron': 10.53, 'i': 0, 'we': 10.53, 'you': 0, 'shehe': 0, 'they': 0, 'ipron': 5.26, 'det': 5.26, 'article': 0, 'number': 0, 'prep': 21.05, 'auxverb': 5.26, 'adverb': 0, 'conj': 10.53, 'negate': 0, 'verb': 10.53, 'adj': 0, 'quantity': 5.26, 'Drives': 15.79, 'affiliation': 15.79, 'achieve': 0, 'power': 0, 'Cognition': 15.79, 'allnone': 0, 'cogproc': 15.79, 'insight': 0, 'cause': 10.53, 'discrep': 5.26, 'tentat': 5.26, 'certitude': 0, 'differ': 0, 'memory': 0, 'Affect': 15.79, 'tone_pos': 5.26, 'tone_neg': 10.53, 'emotion': 10.53, 'emo_pos': 5.26, 'emo_neg': 5.26, 'emo_anx': 5.26, 'emo_anger': 0, 'emo_sad': 0, 'swear': 0, 'Social': 15.79, 'socbehav': 5.26, 'prosocial': 0, 'polite': 0, 'conflict': 5.26, 'moral': 0, 'comm': 0, 'socrefs': 10.53, 'family': 0, 'friend': 0, 'female': 0, 'male': 0, 'Culture': 0, 'politic': 0, 'ethnicity': 0, 'tech': 0, 'Lifestyle': 0, 'leisure': 0, 'home': 0, 'work': 0, 'money': 0, 'relig': 0, 'Physical': 0, 'health': 0, 'illness': 0, 'wellness': 0, 'mental': 0, 'substances': 0, 'sexual': 0, 'food': 0, 'death': 0, 'need': 0, 'want': 5.26, 'acquire': 5.26, 'lack': 0, 'fulfill': 0, 'fatigue': 0, 'reward': 0, 'risk': 0, 'curiosity': 0, 'allure': 10.53, 'Perception': 10.53, 'attention': 0, 'motion': 0, 'space': 10.53, 'visual': 0, 'auditory': 0, 'feeling': 0, 'time': 5.26, 'focuspast': 0, 'focuspresent': 0, 'focusfuture': 5.26, 'Conversation': 0, 'netspeak': 0, 'assent': 0, 'nonflu': 0, 'filler': 0, 'AllPunc': 15.79, 'Period': 5.26, 'Comma': 10.53, 'QMark': 0, 'Exclam': 0, 'Apostro': 0, 'OtherP': 0, 'Emoji': 0}\n\n\n\n\n📁 Analyzing a folder\nThe analyze_folder function allows users to perform a comprehensive analysis of multiple text files located in a specified directory. This function leverages the LIWC tool to extract various linguistic and psychological features from the text data.\n\ndef analyze_folder(self: Liwc,\n                   input_folder: str, \n                   output_location: str, \n                   liwc_dict: str = \"LIWC22\"):\nParameters - input_folder The path to the folder containing text files to be analyzed. This parameter specifies the location of the text data on which the LIWC analysis will be performed.\n\noutput_location The path where the analysis output will be saved. The results will be stored in this location as a CSV file.\nliwc_dict: str Specifies the LIWC dictionary to use for analysis. Defaults to “LIWC22”.\n\nHere’s an example of how to use the analyze_df function:\n\nfrom pyliwc import Liwc\n\n# Initialize the Liwc object with the path to the LIWC CLI executable\nliwc = Liwc('LIWC-22-cli.exe')\n\n# Specify the input folder containing text files and the output location\ninput_folder = '../data/inaugural-address'\noutput_location = '../data/US-president_analysis.csv'\n\n# Perform analysis using the default LIWC22 dictionary\nliwc.analyze_folder(input_folder=input_folder, \n                    output_location=output_location, \n                    liwc_dict='LIWC22')\n\nprint(f\"Analysis completed. Results saved to {output_location}.\")\n\n\n\n💾Analyzing a DataFrame\nThe analyze_df function is a key feature of pyliwc. It allows you to analyze a Pandas DataFrame containing text data. Below is the function signature and its parameters:\n\ndef analyze_df(self: Liwc, \n               text: pd.Series, \n               return_input: bool = False, \n               liwc_dict: str = \"LIWC22\") -&gt; pd.DataFrame\nParameters - text: pd.Series A Pandas Series containing the text data to be analyzed.\n\nreturn_input: bool A boolean flag indicating whether to include the input text in the output DataFrame. Defaults to False.\nliwc_dict: str Specifies the LIWC dictionary to use for analysis. Defaults to “LIWC22”.\n\nReturns - pd.DataFrame A DataFrame containing the LIWC analysis results.\nFunction Workflow 1. Input Conversion: The function takes the input text series and converts it to a temporary CSV file. 2. LIWC Analysis: The function calls the LIWC CLI to perform text analysis, specifying the LIWC dictionary and other parameters. 3. Output Handling: Results are read from the generated CSV output and compiled into a DataFrame.\nHere’s an example of how to use the analyze_df function:\n\nimport pandas as pd\ndf = pd.read_csv('../data/US-president.csv')\ndf\n\n\ndf.columns\n\n\nfrom pyliwc import Liwc\n\nliwc = Liwc('LIWC-22-cli.exe')\n\n# Analyze the text data\nresult_df = liwc.analyze_df(df['Text'], return_input=True, liwc_dict='LIWC22')\n\nThe resulting DataFrame will have several columns corresponding to LIWC categories. Each category provides metrics such as word count, emotional tone, cognitive processes, etc. Here’s a glimpse of what you might see:\n\nWC: Word Count\nAnalytic: Analytical thinking\nClout: Social status and confidence\nAuthentic: Authenticity of the speech\nTone: Emotional tone of the address\n\n\n# Display the result\nresult_df\n\n\nRadar plot\nNow, we’ll use matplotlib to create a radar plot. We’ll customize it to include labels and titles to enhance understanding. For readability, we plot the most recent Presidents.\n\nimport matplotlib.pyplot as plt\nimport numpy as np\n\ncategories = ['Analytic', 'Clout', 'Authentic', 'Tone']\nN = len(categories)\n\n# Compute angles for each axis\nangles = np.linspace(0, 2 * np.pi, N, endpoint=False).tolist()\nangles += angles[:1]  # Complete the loop\n\n# Create radar plot\nfig, ax = plt.subplots(figsize=(8, 8), subplot_kw=dict(polar=True))\n\n# Define colors for each president\ncolors = ['red', 'blue']\n\n# Plot each president's data\nfor i, president in enumerate(df['President'][-2:]):\n    values = result_df.loc[i, categories].tolist()\n    values += values[:1]  # Complete the loop\n    ax.fill(angles, values, color=colors[i], alpha=0.25, label=president)\n    ax.plot(angles, values, color=colors[i], linewidth=2)\n\n# Set the category labels on the axes\nax.set_yticklabels([])\nax.set_xticks(angles[:-1])\nax.set_xticklabels(categories, fontsize=12)\n\n# Add a legend and title\nplt.legend(loc='lower right', bbox_to_anchor=(1.1, 1.1), fontsize=12)\nplt.title('LIWC-22 Analysis of US Presidential Inaugural Addresses', size=15, color='darkblue', weight='bold')\n\n# Display the radar plot\nplt.show()\n\n\n\n\n💬Conducting a Language Style Matching\nThe analyze_lsm function is a key feature of pyliwc. It allows you to analyze Linguistic Style Matching (LSM) based on a Pandas DataFrame containing text data.\n\ndef analyze_lsm(self: Liwc, \n                df: pd.DataFrame, \n                calculate_lsm: str = \"person-and-group\", \n                group_column: str = 'GroupID', \n                person_column: str = 'PersonID', \n                text_column: str = 'Text', \n                output_type: str = \"pairwise\",\n                expanded_output: bool = False, \n                omit_speakers_number_of_turns: int = 0, \n                omit_speakers_word_count: int = 10, \n                segmentation: str = \"none\"\n               ) -&gt; Union[pd.DataFrame, dict]:\nParameters\n\ndf: pd.DataFrame A Pandas DataFrame containing the text data to be analyzed.\ncalculate_lsm: str Sets the type of LSM calculation. Options are:\n\n“person”: Calculate only person-level LSM.\n“group”: Calculate only group-level LSM.\n“person-and-group”: Calculate both person and group-level LSM. Default is “person-and-group”.\n\ngroup_column: str The column name in df representing the Group ID. Default is ‘GroupID’.\nperson_column: str The column name in df representing the Person ID. Default is ‘PersonID’.\ntext_column: str The column name in df representing the text data. Default is ‘Text’.\noutput_type: str Sets the type of output. Default is “pairwise”. Options are:\n\n“one-to-many”: One-to-many comparison.\n“pairwise”: Pairwise comparison.\n\nexpanded_output: bool Adds an option to get an expanded LSM output. Default is False.\nomit_speakers_word_count: int Omit speakers if the word count is less than this value. Default is 10.\nsegmentation: str Segmentation options for splitting the text. Default is “none”. Options are:\n\n“none”: No segmentation.\n“not=”: Number of turns per segment.\n“nofst=”: Number of segments by speaker turn.\n“nofwc=”: Number of segments by word count.\n“now=”: Number of words per segment.\n“boc=”: Segmentation based on characters.\n“regexp=”: Segmentation based on a regular expression.\n\n\nReturns - pd.DataFrame, dict]\nThe resulting LSM analysis. The output format depends on the specified output_format. Function Workflow\nHere’s an example of how to use the analyze_lsm function with a sample DataFrame:\n\nfrom pyliwc import Liwc\nimport pandas as pd\n\nliwc = Liwc('LIWC-22-cli.exe')\n\ndf = pd.read_csv('../data/US-president.csv')\n\nlsm = liwc.analyze_lsm(\n    df=df, \n    calculate_lsm=\"person-and-group\", \n    group_column='Party', \n    person_column='President', \n    text_column='Text', \n    output_type=\"pairwise\", \n    expanded_output=False, \n    omit_speakers_number_of_turns=0, \n    omit_speakers_word_count=10, \n    segmentation=\"none\"\n)\n\n\nlsm['person_level']\n\n\nlsm['group_level']\n\n\n\n📊Conducting a Narrative Arc Analysis\nThe narrative_arc allows you to analyze the narrative arc of text data based on a Pandas DataFrame.\ndef narrative_arc(self: Liwc, df: pd.DataFrame, column_names: Union[list, None] = None, \n                  output_individual_data_points: bool = True, scaling_method: str = '0-100', \n                  segments_number: int = 5, skip_wc: int = 10) -&gt; pd.DataFrame:\nParameters\n\ndf: pd.DataFrame A Pandas DataFrame containing the text data to be analyzed.\ncolumn_names: List of column names in df that should be processed. If None, all columns are processed. Default is None.\noutput_individual_data_points: If True, outputs individual data points for each segment. If False, aggregates the data. Default is True.\nscaling_method: Method for scaling the data. Options are:\n\n\"0-100\": Scale values between 0 and 100.\n\"Z-score\": Scale values using Z-score normalization. Default is “0-100”.\n\nsegments_number: int Number of segments into which the text is divided for analysis. Default is 5.\nskip_wc: int Skip any texts with a word count less than this value. Default is 10.\n\nReturns\n\npd.DataFrame The resulting DataFrame with the narrative arc analysis.\n\n\nfrom pyliwc import Liwc\nimport pandas as pd\n\nliwc = Liwc('LIWC-22-cli.exe')\n\ndf = pd.read_csv('../data/US-president.csv')\n\narc = liwc.narrative_arc(\n    df=df, \n    column_names=['Text'], \n    output_individual_data_points=True, \n    scaling_method='0-100', \n    segments_number=5\n)\n\n\nfrom IPython.display import display\n\nfor i, president in enumerate(df.President.tolist()):\n    fig = liwc.plot_narrative_arc(df=arc[arc.index == i], legend_labels=[president])\n    fig.suptitle(president, y=1.05, fontweight='bold')\n    display(fig)",
    "crumbs": [
      "Tutorials",
      "Text Analysis of U.S. Presidents' Inaugural Addresses"
    ]
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Welcome to pyliwc",
    "section": "",
    "text": "Overview\nPyLIWC is a Python package designed to provide an interface for analyzing text using the LIWC (Linguistic Inquiry and Word Count) tool. This package allows users to interact with the LIWC CLI from within Python, offering features for processing various data formats, performing linguistic style matching, and analyzing narrative arcs in text data. It can handle folders, text files or Pandas dataframes.\nAs the LIWC dictionary is proprietary software, this requires that you have installed the latest version of the LIWC software on your machine, with an activated licence (academic licence).\n\n\nManifest\nThe LIWC (Linguistic Inquiry and Word Count) software by James W. Pennebaker, Roger J. Booth, and Martha E. Francis has been instrumental for countless researchers in analyzing linguistic and psycholinguistic data. Linguistic Inquiry and Word Count (LIWC) is the gold standard of dictionary-based approaches for analyzing word use. It can be used to study a single individual, groups of people over time, or all of social media.However, LIWC has traditionally been available through software, necessitating the usage of an outside software to the Python environement.\nRecognizing the growing popularity of Python in the scientific and research community, there is an important need for researchers and data scientists for integrating LIWC directly into their Python workflows. Thus, pyliwc brings (many of) the functionality of LIWC to a wider audience without the need use the LIWC application as GUI. pyliwc is open-source, released under the MIT license, and is designed to enable researchers to perform sophisticated linguistic analysis directly in Python.\n\n\nFeatures\nThe package offers a wide range of features, including:\n\nLIWC Text Analysis:\n\n\nAnalyze text data from various sources, including CSV files, directories, Pandas DataFrames, and individual strings.\nSupports internal dictionaries (e.g., LIWC22, LIWC2015) as well as adhoc dictionaries\nOutput results directly in a convenient Pandas DataFrame for easy integration with other data processing tools.\n\n\nLinguistic Style Matching (LSM):\n\n\nPerform person and group-level LSM analysis using a DataFrame to evaluate the alignment of linguistic styles in conversational data.\nSupports pairwise LSM calculations for detailed analysis of interpersonal communication dynamics.\n\n\nNarrative Arc Analysis:\n\n\nAnalyze the narrative arc of text data to understand staging, progression, and cognitive tension, offering deep insights into storytelling elements.\nGraphics capabilities are included, allowing users to visualize narrative structures: staging, plot progression, and cognitive tension over time.\nProvides customizable scaling methods and segment options for precise control over the analysis process.\n\n\nIntegration with LIWC CLI: Seamlessly execute LIWC commands and capture output for further processing, leveraging the full power of LIWC’s linguistic analysis capabilities. Multithreading support for improved performance and faster analysis across large datasets.\nOutput Options: Flexible output formats, including CSV, JSON, and direct integration with Pandas DataFrames, ensuring compatibility with a wide range of data analysis workflows.\n\n\nMissing Features: In the current version, the following features have not yet been ported : Word frequencies, Meaning extraction and Contextualizer.",
    "crumbs": [
      "Welcome to `pyliwc`"
    ]
  },
  {
    "objectID": "core.html",
    "href": "core.html",
    "title": "API reference",
    "section": "",
    "text": "source\n\n\n\n Liwc (liwc_cli_path:str='LIWC-22-cli', threads:Optional[int]=None,\n       verbose:bool=False)\n\nInitialize the LIWC Class.\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\nliwc_cli_path\nstr\nLIWC-22-cli\nLIWC CLI Path.\n\n\nthreads\nOptional\nNone\nNumber of threads to use. Defaults to the number of CPU cores minus one.\n\n\nverbose\nbool\nFalse\nDisplay printing and progress bar. Defaults to False.",
    "crumbs": [
      "API reference"
    ]
  },
  {
    "objectID": "core.html#initialization",
    "href": "core.html#initialization",
    "title": "API reference",
    "section": "",
    "text": "source\n\n\n\n Liwc (liwc_cli_path:str='LIWC-22-cli', threads:Optional[int]=None,\n       verbose:bool=False)\n\nInitialize the LIWC Class.\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\nliwc_cli_path\nstr\nLIWC-22-cli\nLIWC CLI Path.\n\n\nthreads\nOptional\nNone\nNumber of threads to use. Defaults to the number of CPU cores minus one.\n\n\nverbose\nbool\nFalse\nDisplay printing and progress bar. Defaults to False.",
    "crumbs": [
      "API reference"
    ]
  },
  {
    "objectID": "core.html#liwc-analysis",
    "href": "core.html#liwc-analysis",
    "title": "API reference",
    "section": "LIWC Analysis",
    "text": "LIWC Analysis\n\nsource\n\nLiwc.analyze_string_to_json\n\n Liwc.analyze_string_to_json (input_string:str, liwc_dict:str='LIWC22')\n\n*Analyze a single string and return the result as JSON.\nReturns: dict:*\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\ninput_string\nstr\n\nThe string to analyze.\n\n\nliwc_dict\nstr\nLIWC22\nDictionary to use for analysis. Defaults to “LIWC22”.\n\n\nReturns\ndict\n\nAnalysis results in JSON format.\n\n\n\n\nsource\n\n\nLiwc.analyze_string\n\n Liwc.analyze_string (input_string:str, output_location:str,\n                      liwc_dict:str='LIWC22')\n\nAnalyze a single string using LIWC and save to csv.\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\ninput_string\nstr\n\nThe string to analyze.\n\n\noutput_location\nstr\n\nPath to save the analysis output (.csv).\n\n\nliwc_dict\nstr\nLIWC22\n\n\n\nReturns\nNone\n\nDictionary to use for analysis. Defaults to “LIWC22”.\n\n\n\n\nsource\n\n\nLiwc.analyze_df\n\n Liwc.analyze_df (text:pandas.core.series.Series, return_input:bool=False,\n                  liwc_dict:str='LIWC22')\n\nAnalyze text data from a DataFrame using LIWC.\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\ntext\nSeries\n\nPandas Series containing text data.\n\n\nreturn_input\nbool\nFalse\nWhether to return the input text with the output. Defaults to False.\n\n\nliwc_dict\nstr\nLIWC22\nDictionary to use for analysis. Defaults to “LIWC22”.\n\n\nReturns\nDataFrame\n\npd.DataFrame: DataFrame containing the analysis results.\n\n\n\n\nsource\n\n\nLiwc.analyze_folder\n\n Liwc.analyze_folder (input_folder:str, output_location:str,\n                      liwc_dict:str='LIWC22')\n\nAnalyze all text files in a folder using LIWC.\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\ninput_folder\nstr\n\nPath to the folder containing text files.\n\n\noutput_location\nstr\n\nPath to save the analysis output.\n\n\nliwc_dict\nstr\nLIWC22\n\n\n\nReturns\nNone\n\nDictionary to use for analysis. Defaults to “LIWC22”.\n\n\n\n\nsource\n\n\nLiwc.analyze_csv\n\n Liwc.analyze_csv (input_file:str, output_location:str,\n                   row_id_indices:str, column_indices:str,\n                   liwc_dict:str='LIWC22')\n\nAnalyze text data from a CSV file using LIWC.\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\ninput_file\nstr\n\nPath to the input CSV file.\n\n\noutput_location\nstr\n\nPath to save the analysis output.\n\n\nrow_id_indices\nstr\n\nIndices of row IDs in the CSV.\n\n\ncolumn_indices\nstr\n\nIndices of text columns in the CSV.\n\n\nliwc_dict\nstr\nLIWC22\n\n\n\nReturns\nNone\n\nDictionary to use for analysis. Defaults to “LIWC22”.\n\n\n\n\n# liwc = Liwc('LIWC-22-cli.exe', verbose=True)\n# s = \"As Leclerc entered the Invalides, with his cortege of exaltation in the sun of Africa and the battles of Alsace, enter here, Jean Moulin, with your terrible cortege.\"\n# r = liwc.analyze_string_to_json(s)\n\n\n# desired_keys = ['WC', 'Analytic', 'Clout', 'Authentic', 'Tone']\n# filtered_dict = {key: r[key] for key in desired_keys if key in r}\n# print(filtered_dict)",
    "crumbs": [
      "API reference"
    ]
  },
  {
    "objectID": "core.html#language-style-matching",
    "href": "core.html#language-style-matching",
    "title": "API reference",
    "section": "Language Style Matching",
    "text": "Language Style Matching\n\nsource\n\nLiwc.analyze_lsm\n\n Liwc.analyze_lsm (df:pandas.core.frame.DataFrame,\n                   calculate_lsm:str='person-and-group',\n                   group_column:str='GroupID',\n                   person_column:str='PersonID', text_column:str='Text',\n                   output_type:str='pairwise', expanded_output:bool=False,\n                   omit_speakers_number_of_turns:int=0,\n                   omit_speakers_word_count:int=10,\n                   segmentation:str='none', wsl_mode:bool=True)\n\nAnalyzes Linguistic Style Matching (LSM) based on the provided DataFrame.\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\ndf\nDataFrame\n\nInput DataFrame containing the text data to be analyzed.\n\n\ncalculate_lsm\nstr\nperson-and-group\nSets the type of LSM calculation. Options are:- “person”: Calculate only person-level LSM.- “group”: Calculate only group-level LSM.- “person-and-group”: Calculate both person and group-level LSM.Default is “person-and-group”.\n\n\ngroup_column\nstr\nGroupID\nThe column name in df representing the Group ID. Default is ‘GroupID’.\n\n\nperson_column\nstr\nPersonID\nThe column name in df representing the Person ID. Default is ‘PersonID’.\n\n\ntext_column\nstr\nText\nThe column name in df representing the text data. Default is ‘Text’.\n\n\noutput_type\nstr\npairwise\nSets the type of output. Options are:- “one-to-many”: One-to-many comparison.- “pairwise”: Pairwise comparison.Default is “pairwise”.\n\n\nexpanded_output\nbool\nFalse\nAdds an option to get an expanded LSM output. Default is False.\n\n\nomit_speakers_number_of_turns\nint\n0\n\n\n\nomit_speakers_word_count\nint\n10\nOmit speakers if the word count is less than this value. Default is 10.\n\n\nsegmentation\nstr\nnone\nSegmentation options for splitting the text. Options are:- “none”: No segmentation.- “not=”: Number of turns per segment.- “nofst=”: Number of segments by speaker turn.- “nofwc=”: Number of segments by word count.- “now=”: Number of words per segment.- “boc=”: Segmentation based on characters.- “regexp=”: Segmentation based on a regular expression.Default is “none”.\n\n\nwsl_mode\nbool\nTrue\nWhether to convert paths for WSL. Defaults to True.\n\n\nReturns\nUnion\n\nThe resulting LSM analysis. The output format depends on the specified output_format.",
    "crumbs": [
      "API reference"
    ]
  },
  {
    "objectID": "core.html#narrative-arc",
    "href": "core.html#narrative-arc",
    "title": "API reference",
    "section": "Narrative arc",
    "text": "Narrative arc\n\nsource\n\nLiwc.plot_narrative_arc\n\n Liwc.plot_narrative_arc (df:pandas.core.frame.DataFrame,\n                          legend_labels:list=None)\n\nPlots the narrative arc for the given DataFrame, showing Staging, Plot Progression, and Cognitive Tension.\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\ndf\nDataFrame\n\nInput DataFrame containing the narrative arc data.Note: ‘output_individual_data_points=True’ in narrative_arc to get all required data to plot the narractive arc.\n\n\nlegend_labels\nlist\nNone\nList of labels for the legend, corresponding to each row in the DataFrame.\n\n\nReturns\nFigure\n\nThe resulting plot figure of the narrative arcs.\n\n\n\n\nsource\n\n\nLiwc.narrative_arc\n\n Liwc.narrative_arc (df:pandas.core.frame.DataFrame,\n                     column_names:Optional[list]=None,\n                     output_individual_data_points:bool=True,\n                     scaling_method:str='0-100', segments_number:int=5,\n                     skip_wc:int=10)\n\nAnalyzes the narrative arc of text data based on the provided DataFrame.\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\ndf\nDataFrame\n\nInput DataFrame containing the text data to be analyzed.\n\n\ncolumn_names\nOptional\nNone\nList of column names in df that should be processed. If None, all columns are processed. Default is None.\n\n\noutput_individual_data_points\nbool\nTrue\nIf True, outputs individual data points for each segment. If False, aggregates the data. Default is True.\n\n\nscaling_method\nstr\n0-100\nMethod for scaling the data. Options are:- “0-100”: Scale values between 0 and 100.- “Z-score”: Scale values using Z-score normalization.Default is “0-100”.\n\n\nsegments_number\nint\n5\nNumber of segments into which the text is divided for analysis. Default is 5.\n\n\nskip_wc\nint\n10\nSkip any texts with a word count less than this value. Default is 10.\n\n\nReturns\nDataFrame\n\nThe resulting DataFrame with the narrative arc analysis.",
    "crumbs": [
      "API reference"
    ]
  }
]